{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull down known DGA domains from: \n",
    "\n",
    "http://osint.bambenekconsulting.com/feeds/dga-feed.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# target_url = 'https://ransomwaretracker.abuse.ch/downloads/RW_URLBL.txt'\n",
    "# txt = urllib.urlopen(target_url).read()\n",
    "\n",
    "import urllib.request\n",
    "with urllib.request.urlopen(\"https://ransomwaretracker.abuse.ch/downloads/RW_URLBL.txt\") as url:\n",
    "    s = url.read()\n",
    "\n",
    "#features \n",
    "full_grab = str(s).split('\\\\n') \n",
    "dga_list = str(s).split('\\\\n')[7:]\n",
    "timestamp = str(s).split('\\\\n')[2]\n",
    "name_of_list = str(s).split('\\\\n')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of dga_list\n",
    "import pandas as pd\n",
    "dga_list = pd.DataFrame(dga_list)\n",
    "dga_list.columns = ['url']\n",
    "#load only first 10,000 lines\n",
    "dga_list = dga_list[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get today's date\n",
    "import datetime\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(now)\n",
    "#dga_list.to_csv()\n",
    "import pandas as pd\n",
    "dga_list = pd.DataFrame(dga_list)\n",
    "dga_list.to_csv('dga_domains_' + now + '.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#domain report \n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "start = time.time()\n",
    "print(start)\n",
    "\n",
    "url = 'https://www.virustotal.com/vtapi/v2/domain/report'\n",
    "#domain = ['www.coropeppinumereu.it']\n",
    "f = open('dga_domains_' + now + '.txt', 'r')\n",
    "domains = f.readlines()\n",
    "domains = [d.strip() for d in domains]\n",
    "domains = [i.strip('http://') for i in domains]\n",
    "sep = '/'\n",
    "domains = [s.split(sep, 1)[0] for s in domains]\n",
    "domains.pop(0)\n",
    "\n",
    "\n",
    "for value in domains:\n",
    "    params = {'domain': value, 'apikey': ''}\n",
    "    headers = {\n",
    "      \"Accept-Encoding\": \"gzip, deflate\",\n",
    "      \"User-Agent\" : \"gzip,  My python example client or username\"\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers).json()\n",
    "    data = response\n",
    "    json_normalize(data)\n",
    "    \n",
    "    \n",
    "    with open('dga_domains_' + now + '.json', 'a') as outfile:\n",
    "        json.dump(data, outfile, ensure_ascii=True)\n",
    "        print(data)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "end = time.time()\n",
    "print(end)\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json    \n",
    "\n",
    "domain_data = []\n",
    "with open('dga_domains_' + now + '.json') as f:\n",
    "    for line in f:\n",
    "        domain_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "dga_report = json_normalize(domain_data)\n",
    "dga_report.head()\n",
    "\n",
    "#write to pickle file \n",
    "dga_report.to_pickle('dga_pickle_' + now + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url report\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "start = time.time()\n",
    "print(start)\n",
    "\n",
    "url = 'https://www.virustotal.com/vtapi/v2/url/report'\n",
    "headers = {\n",
    "  \"Accept-Encoding\": \"gzip, deflate\",\n",
    "  \"User-Agent\" : \"gzip,  My python example client or username\"\n",
    "}\n",
    "\n",
    "# read domains from file and pass them to DomainScanner and DomainReportReader\n",
    "with open('dga_domains_' + now + '.txt', 'r') as infile:  # keeping the file open because it shouldnt\n",
    "                                          # be opened/modified during reading anyway\n",
    "    for value in infile:\n",
    "        value = value.strip('\\n')\n",
    "        print(value)\n",
    "        try:\n",
    "            for value in infile:\n",
    "                params = {\"apikey\": '', \"resource\": value}\n",
    "                response =requests.get(url, params=params, headers=headers).json()\n",
    "                json_response = response\n",
    "                import json\n",
    "                with open('url_report_' + now + '.json', 'a') as outfile:\n",
    "                    json.dump(json_response, outfile)\n",
    "                    outfile.write('\\n')\n",
    "\n",
    "\n",
    "        except Exception as err:  # keeping it\n",
    "            print('Encountered an error but scanning will continue.', err)\n",
    "            pass\n",
    "\n",
    "end = time.time()\n",
    "print(end)\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json    \n",
    "\n",
    "url_report = []\n",
    "with open('url_report_' + now + '.json') as f:\n",
    "    for line in f:\n",
    "        url_report.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "dga_url_report = json_normalize(url_report)\n",
    "dga_url_report.head()\n",
    "\n",
    "#write to pickle file \n",
    "dga_url_report.to_pickle('url_report_' + now + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url parsing \n",
    "#parse url for features\n",
    "\n",
    "#query\n",
    "dga_list = dga_list['url'].replace('(^http\\:\\/\\/)', '', regex=True, inplace=False)\n",
    "dga_list = pd.DataFrame(dga_list)\n",
    "dga_list_query = dga_list[\"url\"].str.split(\"/\", expand = True).rename(columns = lambda x: \"query\"+str(x+1))\n",
    "dga_list = dga_list.join(dga_list_query)\n",
    "\n",
    "\n",
    "#entropy\n",
    "import math\n",
    "\n",
    "\n",
    "def entropy(string):\n",
    "        \"Calculates the Shannon entropy of a string\"\n",
    "\n",
    "        # get probability of chars in string\n",
    "        prob = [ float(string.count(c)) / len(string) for c in dict.fromkeys(list(string)) ]\n",
    "\n",
    "        # calculate the entropy\n",
    "        entropy = - sum([ p * math.log(p) / math.log(2.0) for p in prob ])\n",
    "\n",
    "        return entropy\n",
    "\n",
    "#search for malicious file extension\n",
    "#dga_list[dga_list['url'].str.contains(\"ball\")]\n",
    "searchfor = ['\\.gz','\\.vbs','\\.vbe','\\.7z','\\.exe','\\.js','\\.jar','\\.rar','\\.ace','\\.scr','\\.bat','\\.arj','\\.lnk','\\.mht','mht','wsf','js','fakertf','\\.wsf','\\.xz','Java Archive',\n",
    "'\\.r00','\\.bz','\\.uue','\\.chm','\\.pif','\\.pdf','\\.cab','\\.pub','\\.jse','\\.vbs','vbs','\\.dmg','\\.sfx','\\.py','\\.bat','\\.tmp','\\.vbs','\\.cmd','\\.vbe','\\.jse','\\.lnk','\\.PS1',\n",
    "             '\\.PS1XML','\\.PS2','\\.PS2XML','\\.PSC1','\\.PSC2','\\.inf','\\.msi','\\.msp','\\.gadget','\\.zip']\n",
    "pattern = '|'.join(searchfor)\n",
    "dga_list['mal_ext'] = dga_list['url'].str.contains(pattern)\n",
    "dga_list['file_ext'] = pd.DataFrame(dga_list['url'].str.findall(pattern))\n",
    "\n",
    "\n",
    "\n",
    "#ip address\n",
    "ippattern = (r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\")\n",
    "dga_list['IP'] = dga_list['url'].str.contains(ippattern)\n",
    "\n",
    "#tld\n",
    "tldpattern = (r\"\\.\\w+\\/\")\n",
    "dga_list['tld'] = dga_list['url'].str.findall(tldpattern).astype(str)\n",
    "dga_list['tld'] = dga_list['tld'].replace('[\\[|\\]|\\/|\\.|\\']', '', regex=True, inplace=False)\n",
    "\n",
    "#benign extensions\n",
    "safeext = ['\\.gif','\\.jpg','\\.jpeg','\\.xml','\\.csv','\\.png','\\.p7s','\\.diff','\\.mp4','\\.wav','\\.dat','\\.txt','\\.tif','\\.mp3','\\.tsv', 'JPEG graphics file', \n",
    "'Graphics interchange format file', 'Tagged Image File Format', 'MPEG-1 Audio Layer (MP3) audio file','noextension','Portable Network Graphics file',\n",
    "'csv','txt','xml','\\.ics','Java bytecode file','fp', 'fp_senders_mailfrom', 'fp_sender_from']\n",
    "pattern2 = '|'.join(safeext)\n",
    "dga_list['safe_ext'] = dga_list['url'].str.contains(pattern2, regex=True)\n",
    "\n",
    "dga_list['safe_file_ext'] = pd.DataFrame(dga_list['url'].str.findall(pattern2))\n",
    "dga_list\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
